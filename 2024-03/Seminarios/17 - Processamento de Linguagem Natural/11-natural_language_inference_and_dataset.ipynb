{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6df7980",
   "metadata": {
    "id": "f6df7980"
   },
   "source": [
    "As seguintes bibliotecas adicionais são necessárias para executar este\n",
    "notebook. Observe que a execução no Colab é experimental, por favor, relate um Github\n",
    "questão se você tiver algum problema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cfadfe",
   "metadata": {
    "id": "e6cfadfe"
   },
   "outputs": [],
   "source": [
    "!pip install d2l==1.0.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68096c17",
   "metadata": {
    "id": "68096c17",
    "origin_pos": 0
   },
   "source": [
    "# Inferência de linguagem natural e o conjunto de dados\n",
    ":label:`sec_inferência-de-linguagem-natural-e-conjunto-de-dados`\n",
    "\n",
    "Em :numref:`sec_sentiment`, discutimos o problema da análise de sentimento.\n",
    "Esta tarefa visa classificar uma única sequência de texto em categorias predefinidas,\n",
    "como um conjunto de polaridades de sentimento.\n",
    "No entanto, quando há necessidade de decidir se uma frase pode ser inferida de outra,\n",
    "ou eliminar redundância identificando frases que são semanticamente equivalentes,\n",
    "saber classificar uma sequência de texto é insuficiente.\n",
    "Em vez disso, precisamos ser capazes de raciocinar sobre pares de sequências de texto.\n",
    "\n",
    "\n",
    "## Inferência de linguagem natural\n",
    "\n",
    "*A inferência da linguagem natural* estuda se uma *hipótese*\n",
    "pode ser inferido de uma *premissa*, onde ambos são uma sequência de texto.\n",
    "Em outras palavras, a inferência da linguagem natural determina a relação lógica entre um par de sequências de texto.\n",
    "Esses relacionamentos geralmente se dividem em três tipos:\n",
    "\n",
    "* *Envolvimento*: a hipótese pode ser inferida a partir da premissa.\n",
    "* *Contradição*: a negação da hipótese pode ser inferida da premissa.\n",
    "* *Neutro*: todos os outros casos.\n",
    "\n",
    "A inferência em linguagem natural também é conhecida como tarefa de reconhecimento de implicação textual.\n",
    "Por exemplo, o par a seguir será rotulado como *envolvimento* porque \"mostrar afeição\" na hipótese pode ser inferido de \"abraçar um ao outro\" na premissa.\n",
    "\n",
    "> Premissa: Duas mulheres estão se abraçando.\n",
    "\n",
    "> Hipótese: Duas mulheres estão demonstrando afeição.\n",
    "\n",
    "O seguinte é um exemplo de *contradição*, já que \"executar o exemplo de codificação\" indica \"não dormir\" em vez de \"dormir\".\n",
    "\n",
    "> Premissa: Um homem está executando o exemplo de codificação do Dive into Deep Learning.\n",
    "\n",
    "> Hipótese: O homem está dormindo.\n",
    "\n",
    "O terceiro exemplo mostra uma relação de *neutralidade* porque nem \"famoso\" nem \"não famoso\" podem ser inferidos do fato de \"estarem se apresentando para nós\".\n",
    "\n",
    "> Premissa: Os músicos estão se apresentando para nós.\n",
    "\n",
    "> Hipótese: Os músicos são famosos.\n",
    "\n",
    "A inferência em linguagem natural tem sido um tópico central para a compreensão da linguagem natural.\n",
    "Ele desfruta de amplas aplicações que vão desde\n",
    "recuperação de informações para resposta a perguntas de domínio aberto.\n",
    "Para estudar esse problema, começaremos investigando um conjunto de dados de referência de inferência de linguagem natural popular.\n",
    "\n",
    "\n",
    "## O conjunto de dados de inferência de linguagem natural de Stanford (SNLI)\n",
    "\n",
    "[**Stanford Natural Language Inference (SNLI) Corpus**] é uma coleção de mais de 500.000 pares de frases rotuladas em inglês :cite:`Bowman.Angeli.Potts.ea.2015`.\n",
    "Baixamos e armazenamos o conjunto de dados SNLI extraído no caminho `../data/snli_1.0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a77a4ae",
   "metadata": {
    "id": "2a77a4ae",
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ../data/snli_1.0.zip from https://nlp.stanford.edu/projects/snli/snli_1.0.zip...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "#@save\n",
    "d2l.DATA_HUB['SNLI'] = (\n",
    "    'https://nlp.stanford.edu/projects/snli/snli_1.0.zip',\n",
    "    '9fcde07509c7e87ec61c640c1b2753d9041758e4')\n",
    "\n",
    "data_dir = d2l.download_extract('SNLI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98299766",
   "metadata": {
    "id": "98299766",
    "origin_pos": 3
   },
   "source": [
    "### [**Lendo o conjunto de dados**]\n",
    "\n",
    "O conjunto de dados SNLI original contém informações muito mais ricas do que realmente precisamos em nossos experimentos. Assim, definimos uma função `read_snli` para extrair apenas parte do conjunto de dados e, em seguida, retornar listas de premissas, hipóteses e seus rótulos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15051d2a",
   "metadata": {
    "id": "15051d2a",
    "origin_pos": 4,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "def read_snli(data_dir, is_train):\n",
    "    \"\"\"Read the SNLI dataset into premises, hypotheses, and labels.\"\"\"\n",
    "    def extract_text(s):\n",
    "        # Remove information that will not be used by us\n",
    "        s = re.sub('\\\\(', '', s)\n",
    "        s = re.sub('\\\\)', '', s)\n",
    "        # Substitute two or more consecutive whitespace with space\n",
    "        s = re.sub('\\\\s{2,}', ' ', s)\n",
    "        return s.strip()\n",
    "    label_set = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
    "    file_name = os.path.join(data_dir, 'snli_1.0_train.txt'\n",
    "                             if is_train else 'snli_1.0_test.txt')\n",
    "    with open(file_name, 'r') as f:\n",
    "        rows = [row.split('\\t') for row in f.readlines()[1:]]\n",
    "    premises = [extract_text(row[1]) for row in rows if row[0] in label_set]\n",
    "    hypotheses = [extract_text(row[2]) for row in rows if row[0] in label_set]\n",
    "    labels = [label_set[row[0]] for row in rows if row[0] in label_set]\n",
    "    return premises, hypotheses, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5708690",
   "metadata": {
    "id": "c5708690",
    "origin_pos": 5
   },
   "source": [
    "Agora vamos [**imprimir os 3 primeiros pares**] de premissa e hipótese, bem como seus rótulos (\"0\", \"1\" e \"2\" correspondem a \"implicação\", \"contradição\" e \"neutro\", respectivamente).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c2e177a",
   "metadata": {
    "id": "2c2e177a",
    "origin_pos": 6,
    "outputId": "1e88e879-3e25-4a87-ceaa-7a8985113c9d",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "premise: A person on a horse jumps over a broken down airplane .\n",
      "hypothesis: A person is training his horse for a competition .\n",
      "label: 2\n",
      "premise: A person on a horse jumps over a broken down airplane .\n",
      "hypothesis: A person is at a diner , ordering an omelette .\n",
      "label: 1\n",
      "premise: A person on a horse jumps over a broken down airplane .\n",
      "hypothesis: A person is outdoors , on a horse .\n",
      "label: 0\n"
     ]
    }
   ],
   "source": [
    "train_data = read_snli(data_dir, is_train=True)\n",
    "for x0, x1, y in zip(train_data[0][:3], train_data[1][:3], train_data[2][:3]):\n",
    "    print('premise:', x0)\n",
    "    print('hypothesis:', x1)\n",
    "    print('label:', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02260619",
   "metadata": {
    "id": "02260619",
    "origin_pos": 7
   },
   "source": [
    "O conjunto de treinamento tem cerca de 550.000 pares,\n",
    "e o conjunto de teste tem cerca de 10.000 pares.\n",
    "O seguinte mostra que\n",
    "os três [**rótulos \"impacto\", \"contradição\" e \"neutro\" estão equilibrados**] em\n",
    "tanto o conjunto de treinamento quanto o conjunto de teste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3399eb6f",
   "metadata": {
    "id": "3399eb6f",
    "origin_pos": 8,
    "outputId": "6f682a1e-2878-46b1-eb4c-ffa49aca582d",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[183416, 183187, 182764]\n",
      "[3368, 3237, 3219]\n"
     ]
    }
   ],
   "source": [
    "test_data = read_snli(data_dir, is_train=False)\n",
    "for data in [train_data, test_data]:\n",
    "    print([[row for row in data[2]].count(i) for i in range(3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0daebd",
   "metadata": {
    "id": "aa0daebd",
    "origin_pos": 9
   },
   "source": [
    "### [**Definindo uma classe para carregar o conjunto de dados**]\n",
    "\n",
    "Abaixo, definimos uma classe para carregar o conjunto de dados SNLI herdando da classe `Dataset` no Gluon. O argumento `num_steps` no construtor da classe especifica o comprimento de uma sequência de texto para que cada minibatch de sequências tenha o mesmo formato.\n",
    "Em outras palavras,\n",
    "Os tokens após os primeiros `num_steps` em sequências mais longas são cortados, enquanto os tokens especiais “&lt;pad&gt;” serão acrescentados a sequências mais curtas até que seu comprimento se torne `num_steps`.\n",
    "Ao implementar a função `__getitem__`, podemos acessar arbitrariamente a premissa, hipótese e rótulo com o índice `idx`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3dd55aa",
   "metadata": {
    "id": "d3dd55aa",
    "origin_pos": 11,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "class SNLIDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"A customized dataset to load the SNLI dataset.\"\"\"\n",
    "    def __init__(self, dataset, num_steps, vocab=None):\n",
    "        self.num_steps = num_steps\n",
    "        all_premise_tokens = d2l.tokenize(dataset[0])\n",
    "        all_hypothesis_tokens = d2l.tokenize(dataset[1])\n",
    "        if vocab is None:\n",
    "            self.vocab = d2l.Vocab(all_premise_tokens + all_hypothesis_tokens,\n",
    "                                   min_freq=5, reserved_tokens=['<pad>'])\n",
    "        else:\n",
    "            self.vocab = vocab\n",
    "        self.premises = self._pad(all_premise_tokens)\n",
    "        self.hypotheses = self._pad(all_hypothesis_tokens)\n",
    "        self.labels = torch.tensor(dataset[2])\n",
    "        print('read ' + str(len(self.premises)) + ' examples')\n",
    "\n",
    "    def _pad(self, lines):\n",
    "        return torch.tensor([d2l.truncate_pad(\n",
    "            self.vocab[line], self.num_steps, self.vocab['<pad>'])\n",
    "                         for line in lines])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.premises[idx], self.hypotheses[idx]), self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.premises)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99d881e",
   "metadata": {
    "id": "a99d881e",
    "origin_pos": 12
   },
   "source": [
    "### [**Juntando tudo**]\n",
    "\n",
    "Agora podemos invocar a função `read_snli` e a classe `SNLIDataset` para baixar o conjunto de dados SNLI e retornar instâncias `DataLoader` para conjuntos de treinamento e teste, juntamente com o vocabulário do conjunto de treinamento.\n",
    "Vale ressaltar que devemos utilizar o vocabulário construído a partir do conjunto de treinamento\n",
    "como o do conjunto de teste.\n",
    "Como resultado, qualquer novo token do conjunto de teste será desconhecido para o modelo treinado no conjunto de treinamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af25e511",
   "metadata": {
    "id": "af25e511",
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "def load_data_snli(batch_size, num_steps=50):\n",
    "    \"\"\"Download the SNLI dataset and return data iterators and vocabulary.\"\"\"\n",
    "    num_workers = d2l.get_dataloader_workers()\n",
    "    data_dir = d2l.download_extract('SNLI')\n",
    "    train_data = read_snli(data_dir, True)\n",
    "    test_data = read_snli(data_dir, False)\n",
    "    train_set = SNLIDataset(train_data, num_steps)\n",
    "    test_set = SNLIDataset(test_data, num_steps, train_set.vocab)\n",
    "    train_iter = torch.utils.data.DataLoader(train_set, batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=num_workers)\n",
    "    test_iter = torch.utils.data.DataLoader(test_set, batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=num_workers)\n",
    "    return train_iter, test_iter, train_set.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52342d52",
   "metadata": {
    "id": "52342d52",
    "origin_pos": 15
   },
   "source": [
    "Aqui definimos o tamanho do lote para 128 e o comprimento da sequência para 50,\n",
    "e invoque a função `load_data_snli` para obter os iteradores de dados e o vocabulário.\n",
    "Depois imprimimos o tamanho do vocabulário.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16d10217",
   "metadata": {
    "id": "16d10217",
    "origin_pos": 16,
    "outputId": "57f0e632-62f9-471b-95fb-b43e9da959ce",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 549367 examples\n",
      "read 9824 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Aprendizado Profundo/Processamento de Linguagem Natural/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18678"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "18678"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter, test_iter, vocab = load_data_snli(128, 50)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fba2f1",
   "metadata": {
    "id": "57fba2f1",
    "origin_pos": 17
   },
   "source": [
    "Agora imprimimos o formato do primeiro minibatch.\n",
    "Ao contrário da análise de sentimentos,\n",
    "temos duas entradas `X[0]` e `X[1]` representando pares de premissas e hipóteses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f3cf1e7",
   "metadata": {
    "id": "4f3cf1e7",
    "origin_pos": 18,
    "outputId": "279259f4-34c0-4a87-bb9f-486ce1240ded",
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 50])\n",
      "torch.Size([128, 50])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for X, Y in train_iter:\n",
    "    print(X[0].shape)\n",
    "    print(X[1].shape)\n",
    "    print(Y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85258a9e",
   "metadata": {
    "id": "85258a9e",
    "origin_pos": 19
   },
   "source": [
    "## Resumo\n",
    "\n",
    "* A inferência em linguagem natural estuda se uma hipótese pode ser inferida a partir de uma premissa, onde ambas são uma sequência de texto.\n",
    "* Na inferência em linguagem natural, as relações entre premissas e hipóteses incluem implicação, contradição e neutralidade.\n",
    "* O Stanford Natural Language Inference (SNLI) Corpus é um conjunto de dados de referência popular de inferência de linguagem natural.\n",
    "\n",
    "\n",
    "## Exercícios\n",
    "\n",
    "1. A tradução automática tem sido avaliada há muito tempo com base na correspondência superficial de $n$-gramas entre uma tradução de saída e uma tradução de verdade fundamental. Você pode projetar uma medida para avaliar resultados de tradução automática usando inferência de linguagem natural?\n",
    "1. Como podemos alterar hiperparâmetros para reduzir o tamanho do vocabulário?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f98055e",
   "metadata": {
    "id": "2f98055e",
    "origin_pos": 21,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussões](https://discuss.d2l.ai/t/1388)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (deep_learning)",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
